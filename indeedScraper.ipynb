{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Getter\n",
    "Scrapes Indeed job postings, saves info to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We need *requests* to get our data, *BeautifulSoup* to parse our HTML, and *selenium* to programmatically nagivate Chrome. Last, we will use *openpyxl* to save everything to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_summary(arr):\n",
    "    \"\"\"Removes \\n char from the html elts \n",
    "    with class .summary\"\"\"\n",
    "    new_str = \"\"\n",
    "    if len(arr) <= 1:\n",
    "        clean_str = arr[0].strip('\\n').strip()                        \n",
    "        new_str += clean_str\n",
    "        return new_str\n",
    "    for s in arr:\n",
    "        try:\n",
    "            clean_str = s.strip('\\n').strip()                        \n",
    "            new_str += clean_str\n",
    "        except:\n",
    "            new_str += s.contents[0].string\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def last_row_index(sheet):\n",
    "    \"\"\"receives Excel worksheet and returns an int that represents the \n",
    "    last occupied row of the first column of that sheet\"\"\" \n",
    "    try:\n",
    "        curr_cell = 0\n",
    "        for row in sheet.iter_rows(min_row=1,max_col=1):\n",
    "            for cell in row:                           \n",
    "                curr_cell = cell.row\n",
    "        return curr_cell      \n",
    "    except:\n",
    "        print(\"Invalid excel sheet\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_job_req(url):\n",
    "    \"\"\"Makes a req, returns False if\n",
    "    req status-code is not 200\"\"\"\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(\"Invalid HTTP request from given URL\")\n",
    "        return False\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_job_divs(req):\n",
    "    \"\"\"Takes in a request object from Indeed,\n",
    "    returns divs containg job data\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        jobs = new_soup.find_all(\"div\", class_=\"result\")\n",
    "    except:\n",
    "        print(\"Invalid request object\")\n",
    "        return False\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_job_list(job_divs):\n",
    "    \"\"\"\"\"\"\n",
    "    job_list = []\n",
    "    for i, j in enumerate(job_divs):\n",
    "        new_job = {}\n",
    "        new_job_summary = job_divs[i].find_all('div', class_='summary')[0].contents\n",
    "        new_job['id'] = i\n",
    "        new_job['summary'] = clean_summary(new_job_summary)\n",
    "        new_job['title'] = job_divs[i].find_all('a')[0]['title']\n",
    "        new_job['link'] = 'https://indeed.com' + job_divs[0].find_all('a')[0]['href']\n",
    "\n",
    "        job_list.append(new_job)\n",
    "    \n",
    "    return job_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_jobs(sheet, jobs, file_name):\n",
    "    try:\n",
    "        last_row = last_row_index(ws) + 1\n",
    "        for job in jobs:    \n",
    "            curr_col = 1\n",
    "            for val in job.values():\n",
    "                d = ws.cell(row=(job['id']+last_row), column=curr_col)\n",
    "                d.value = val        \n",
    "                curr_col+=1        \n",
    "    except:\n",
    "        return \"There was an err\"\n",
    "    \n",
    "    wb.save(file_name)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using chrome, but there are other options. Check the Selenium docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test to make sure the request worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Search | Indeed'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.get('https://www.indeed.com/')\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the job you want to search as a string to the `input` with `name:\"q\"` then press *RETURN* to search for jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_job = \"web developer\"\n",
    "\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.send_keys(curr_job)\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple test to see the the query parameter contains our job. *Indeed* will use your location for the \"where\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=web+developer&l=Dumont%2C+NJ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "Now that we have our url, lets grab our HTML using `requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure the req was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_string = driver.current_url\n",
    "\n",
    "new_req = requests.get(req_string)\n",
    "new_req.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "BeautifulSoup provides an awesome API for navigating HTML. This is how we will get the content from our search results and build our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_soup = BeautifulSoup(new_req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_divs = new_soup.find_all(\"div\", class_=\"result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how many jobs we are listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Jobs List\n",
    "Here we a building a list of jobs were each job in dictionary with the following keys:\n",
    "- id\n",
    "    - used to index the job in excel\n",
    "- summary\n",
    "    - a short summary of the job\n",
    "- title\n",
    "    - job title\n",
    "- link\n",
    "    - link to the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'link': 'https://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DnIQaT9_ideK20aGE-Gf5L-4mEV8Q0k7vqCcpbdP_vWWm99hxL5_fHY4xpZMP0Uhx5zsIIHC2JpM0ZxkCrbuPTXhftT08i6R8KTyzH84kb8ZTW1mFYdSyTp3t2dAwbTXA_-AAsx2CykGScHxOgvP7ajg4IWG4-yGRciVuEGMhx3H3X4ZwTs2TjxYzzz73bj0f_5e0yY9Bc6AUfFgYhSOHQH8NGygLjbJnHnkMXzRMfHLX4OFBdyk_NSqZwJyIDWMo_YxrSRKZXurgbLCPI4olpZNSxBhlaZkj463ATs3zlw4Ebc2_v2-ijqwpw5YvWg89g58scJZFKCCuxkRjMcuzh3nb93fC4P_hEUPeDlrlFZULzCimhBh89yrh2W6g0R9kZM8eYll6KEm8c0TlsFVhsyzPNcnHd_e6BfYty9Wmf-GsftzJae0YeJda4wP25yrtDbXMlz4X2pWXnjmXSSGYLLh2-Vlzr0T3fkHf5sDCi-Yvgp_n1sGKCaQ6B_gcrNvfPRthwpmdh1w==&vjs=3&p=1&fvj=0',\n",
       " 'summary': 'Collaborate with back-enddevelopersto design and build a robust API. Michael Kors is always interested in hearing from talented, globally-minded individuals...',\n",
       " 'title': 'Front-end Developer'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_job_list = []\n",
    "for i, j in enumerate(job_divs):\n",
    "    new_job = {}\n",
    "    new_job_summary = job_divs[i].find_all('div', class_='summary')[0].contents\n",
    "    new_job['id'] = i\n",
    "    new_job['summary'] = clean_summary(new_job_summary)\n",
    "    new_job['title'] = job_divs[i].find_all('a')[0]['title']\n",
    "    new_job['link'] = 'https://indeed.com' + job_divs[0].find_all('a')[0]['href']\n",
    "    \n",
    "    new_job_list.append(new_job)\n",
    "    \n",
    "new_job_list[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sheet with the same title as the current job search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['web developer']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.title = curr_job\n",
    "wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_row = last_row_index(ws) +1\n",
    "for job in new_job_list:    \n",
    "    curr_col = 1\n",
    "    for val in job.values():\n",
    "        d = ws.cell(row=(job['id']+last_row), column=curr_col)\n",
    "        d.value = val        \n",
    "        curr_col+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wb.save('jobs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Selenium again to get the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elem = driver.find_element_by_class_name(\"np\")\n",
    "elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop up not there\n"
     ]
    }
   ],
   "source": [
    "close_pop_up = driver.find_element_by_id('popover-close-link')\n",
    "try:\n",
    "    close_pop_up.click()\n",
    "except:\n",
    "    print('Pop up not there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Looks like we may not need selenium anymore after all -- we can just modify the query parameter for *start*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=web+developer&l=Dumont%2C+NJ&start=10#'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_req = make_job_req(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_divs = make_job_divs(new_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_list = make_job_list(job_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_jobs(ws, jobs=job_list, file=\"jobs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
